<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->

<html>
	<head>
		<title>FilmSceneDesigner</title>
		<meta charset="utf-8" />

        
		<meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="stylesheet" href="assets/css/bulma.min.css">
        <link rel="stylesheet" href="assets/css/bulma-carousel.min.css">
        <link rel="stylesheet" href="assets/css/bulma-slider.min.css">
        <link rel="stylesheet" href="assets/css/bootstrap.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="assets/css/font-awesome.min.css">
        <link rel="stylesheet" href="assets/css/index.css">
        <link rel="stylesheet" href="assets/css/style.css" type="text/css" media="screen,projection" />
        <link rel="stylesheet" href="assets/css/main.css" />
        <link rel="shortcut icon" href="images/opt_icon.png" />

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="assets/js/bulma-carousel.min.js"></script>
        <script src="assets/js/bulma-slider.min.js"></script>
        <script src="assets/js/index.js"></script>
        <script src="assets/js/video_comparison.js"></script>

	</head>
	<body>

		<!-- Home -->
        <div class="wrapper first style1">
            <article class="container" id="home">
                <h2>FilmSceneDesigner: Procedural Film Scene Generation via Multi-Agent Chat</h2>
                <!-- <br>
                <div class="row center">
                    <div class="author col l3 m6 s12"><a href="https://azuxmioy.github.io/" target="_blank">Hsuan-I Ho</a></div>
                    <div class="author col l3 m6 s12"><a href="https://lxxue.github.io/" target="_blank">Lixin Xue</a></div>
                    <div class="author col l3 m6 s12"><a href="https://ait.ethz.ch/people/song" target="_blank">Jie Song</a></div>
                    <div class="author col l3 m6 s12"><a href="https://ait.ethz.ch/people/hilliges" target="_blank">Otmar Hilliges</a></div>
                </div>
                <br> -->
                <!-- <div class="col">
                    <div style="width: 20%; margin: 0em auto 0em auto">
                        <a  href="https://ait.ethz.ch/"><img class="responsive-img" src="images/ait_logo.png"></a>
                    </div>
                    <div class="institute">
                        <a href="https://inf.ethz.ch/" target="_blank">Department of Computer Science</a>,
                        <a href="https://ethz.ch/en.html" target="_blank">ETH Zürich</a>
                    </div>

                </div>
                <br> -->

                <div class="row">
                    <div class="col-sm-6 col-sm-offset-3 text-center">
                        <ul class="nav nav-pills nav-justified">
                            <li>
                                <a href="https://files.ait.ethz.ch/projects/custom-humans/paper.pdf">
                                    <img src="images/icon/Adobe_PDF_icon.svg" width="60px">
                                    <h4><strong>Paper<br>(CVPR 2023)</strong></h4>
                                </a>
                            </li>
                            <li>
                                <a href="https://www.youtube.com/watch?v=aT8ql5hB3ZM">
                                <img src="images/icon/Yt_icon_2017_print.png" width="60px">
                                    <h4><strong>Video</strong></h4>
                                </a>
                            </li>
                            <li>
                                <a href="#download">
                                <image src="images/icon/database-icon.svg" width="50px">
                                    <h4><strong>Dataset</strong></h4>
                                </a>
                            </li>                            
                            <li>
                                <a href="https://github.com/custom-humans/editable-humans" target="_blank">
                                    <image src="images/icon/github.png" width="60px">
                                    <h4><strong>Code<br></strong></h4>
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="container" style="overflow:hidden;">
                    <div id="post_images" class="carousel">
                    
                        <div class="item-1 image-caption-container">
                            <div class="caption">A classical Chinese residence, refined and simple, embodying the understated beauty of Eastern culture.</div>
                            <video poster="" autoplay muted loop playsinline style="pointer-events: none; width: 450px;">
                                <source src="images/out_ancient.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                        </div>
                
                        <div class="item-2 image-caption-container">
                            <div class="caption">"A Southeast Asian-style bedroom with a bright color scheme."</div>
                            <video poster="" autoplay muted loop playsinline style="pointer-events: none; width: 450px;">
                                <source src="images/out_southeast.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                        </div>
                
                        <div class="item-1 image-caption-container">
                            <div class="caption">"A living room from the late 1970s-80s, with a vintage and worn atmosphere, dim, somber color tone."</div>
                            <video poster="" autoplay muted loop playsinline style="pointer-events: none; width: 450px;">
                                <source src="images/out_vintage.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                        </div>
                
                        <div class="item-2 image-caption-container">
                            <div class="caption">"A vintage European-style guest room with warm tones, filled with family atmosphere and a sense of time passing."</div>
                            <video poster="" autoplay muted loop playsinline style="pointer-events: none; width: 450px;">
                                <source src="images/wast.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                        </div>
                    </div>
                </div>


		<!-- Abstract -->
        <div class="wrapper style1">
            <article id="abstract">
                <div class="container">
                    <div class="row center" style="width: 80%; margin: 2em auto 2em auto">
                        <div class="col s10 offset-s1">
                            <img class="responsive-img" src="images/teaser.gif" style="width: 100%"/>
                        </div>                    
                    </div>  
                    <h2>Abstract</h2>
                    <p style="text-align:justify">
                        We propose FilmSceneDesigner, a multi-agent procedural modeling framework for generating film scenes with real-world scale. Given the critical role of scene construction in film production, Set-A-Scene simulates the workflow of professional set designers, enabling procedural scene generation directly within SketchUp software, a widely used tool for film set modeling. Our system takes natural language input with scene attributes such as type, historical period, and style, and generates structured modeling parameters through a multi-agent dialogue and collaboration mechanism. The modeling process follows a structured workflow including floorplan and structure generation, material application, door and window placement, and asset retrieval and arrangement. The generated parameters are then executed using a custom-designed SketchUp-based procedural modeling framework. To enhance cinematic realism, we introduce SetDepot-Pro, a large-scale database comprising 7,000 film-specific digital assets and 1,000 materials, addressing the lack of high-quality datasets tailored for film scene construction. The generated scenes can be used to produce construction drawings for on-site set building, concept art for atmospheric visualization and virtual previs. Experimental results demonstrate that our prompt engineering strategy improves agent decision-making. Furthermore, both qualitative evaluations and user studies show that FilmSceneDesigner produces scenes with greater cinematic realism and aesthetic coherence compared to baseline methods.
                    </p>
                </div>
            </article>
        </div>

		<!-- Paper -->
        <div class="wrapper style1">
            <article id="paper">
                <div class="container">
                
                    <h2>Video</h2>
                    <div class="row center" style="margin: 2em auto 2em auto">
                        <div class="col s10 offset-s1">
                            <div class="youtube-wrapper">
                                <iframe allowfullscreen="allowfullscreen" src="https://www.youtube.com/embed/aT8ql5hB3ZM"></iframe>
                            </div>
                        </div>
                    </div>

                    <h2>Method</h2>
                    <div class="row center" style="width: 100%; margin: 2em auto 2em auto">
                        <div class="col l6 m6 s6">
                            <img class="responsive-img" src="images/rep.gif"/>
                        </div>
                        <div class="col l6 m6 s6">
                            <img class="responsive-img" src="images/query.jpg"/>
                        </div>
                    </div>

                    <h3>Controllable Hybrid Human Representation</h3>
                    <p style="text-align:justify">
                        While neural avatars can be highly realistic, the question of how to edit such avatars remains open.
                        To enable 3D avatars with high-fidelity representational power and local editing capabilities, 
                        we propose a novel hybrid representation that combines the advantages of neural fields
                        (flexibility and modeling power) with LBS-articulated mesh models (ease of deformation and full explicit control).
                        We construct a trainable feature codebook which stores local texture and high-fidelity geometry respectively for each vertex.
                        Training and inference require queries of these features.
                        A query point <i>x<sub>g</sub></i> is projected onto the nearest triangle.
                        The global coordinates are then transformed into triangle coordinates <i>x<sub>l</sub></i>.
                        The triangle’s vertex indices are used to retrieve local texture and geometry features. 

                    </p>

                    <div class="row center" style="width: 100%; margin: 2em auto 2em auto">
                        <div class="col s10 offset-s1">
                            <img class="responsive-img" src="images/fitting.gif" style="width: 100%"/>
                        </div>                    
                    </div>
                    <h3>Avatar Customization by Feature Inversion</h3>
                    <p style="text-align:justify">
                        Our method allows for creating and personalizing avatars with diverse body shapes, appearances, and local
                        details. We leverage the above representation to train a multi-subject model which enables the transfer
                        of local features across subjects. We note that since the mesh topology of the LBS model is identical, this enables
                        us to learn a shared feature space from multiple posed scans. Given a trained model, our method can inverse any unseen 
                        3D scans into feature codebooks. This allows us to locally change either the clothing geometry or appearance of neural 
                        avatars given the corresponding feature indices. It is worth noting that resulting avatars enable detailed pose control 
                        via the SMPL-X parameters without affecting the fitted texture and geometry.
                    </p>
                </div>
            </article>
        </div>




        <!-- Download -->

        <div class="wrapper style1">
            <article id="download">
                <div class="container">
                    <h2>Download</h2>
                    <div class="table-wrapper" align="center">
                        <table>
                            <thead>
                                <tr>
                                    <th></th>
                                    <th>CustomHumans Dataset</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><strong>Download</strong></td>
                                    <td><h6><a href="https://custom-humans.ait.ethz.ch/" target="_blank">Application Link</a></h6></td>
                                </tr>
                                <tr>
                                    <td><strong>Number of Scans</strong></td>
                                    <td><h6>643</h6></td>
                                </tr>
                                <tr>
                                    <td><strong>Number of Subjects</strong></td>
                                    <td><h6>81</h6></td>
                                </tr>
                                <tr>
                                    <td><strong>Number of Garments</strong></td>
                                    <td><h6>125</h6></td>
                                </tr>
                                <tr>
                                    <td><strong>Number of Faces per Mesh</strong></td>
                                    <td><h6>40000</h6></td>
                                </tr>
                                <tr>
                                    <td><strong>Registration</strong></td>
                                    <td><h6>SMPL-X</h6></td>
                                </tr>

                            </tbody>
                        </table>
                    </div>
                </div>

                <div class="container">
                    <div id="mesh-carousel" class="carousel results-carousel" style="height: 150%">
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/001.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/002.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/003.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/004.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/005.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/006.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/007.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/008.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/009.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="item">
                            <video poster="" autoplay controls muted loop height="150%">
                                <source src="images/dataset/010.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>


            </article>
        </div>

        <!-- Results -->


        <div class="wrapper style1">
            <article id="results">
                <div class="container">
                    <h2>Results</h2>
                    <!-- <h3>Avatar Customzation</h3> -->
                    <div class="row center" style="margin-top: 1em" >
                        <div class="col l4 m6 s12">
                            <video class="video" id="mesh1" loop autoplay muted src="images/out_ancient.mp4" onplay="resizeAndPlay(this)"></video>
                        </div>
                        <div class="col l4 m6 s12">
                            <video class="video" id="mesh2" loop autoplay muted src="images/out_southeast.mp4" onplay="resizeAndPlay(this)"></video>
                        </div>
                        <div class="col l4 m6 s12">
                            <video class="video" id="mesh3" loop autoplay muted src="images/out_vintage.mp4" onplay="resizeAndPlay(this)"></video>
                        </div>
                        <div class="col l4 m6 s12">
                            <video class="video" id="mesh3" loop autoplay muted src="images/out_wast.mp4" onplay="resizeAndPlay(this)"></video>
                        </div>
                    </div>
                    <!-- <div class="row center" style="margin-top: 1em" >
                        <div class="col l4 m6 s12">
                            <video class="video" id="mesh4" loop autoplay muted src="images/out-a.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh4Merge"></canvas>
                        </div>
                        <div class="col l4 m6 s12">
                            <video class="video" id="mesh5" loop autoplay muted src="images/out-b.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh5Merge"></canvas>
                        </div>
                        <div class="col l4 m6 s12">
                            <video class="video" id="mesh6" loop autoplay muted src="images/out-c.mp4" onplay="resizeAndPlay(this)"></video>
                            <canvas height=0 class="videoMerge" id="mesh6Merge"></canvas>
                        </div>
                    </div> -->

                    <!-- <h3>Model Fitting Comparison</h3>
                    <div class="row center" style="width: 80%; margin: 1em auto 1em auto" >
                        <img src="images/fitting_compare.jpg">
                    </div> -->

                </div> 
            </article>
        </div>


        <!-- Reference -->
        <div class="wrapper style2">
            <article id="references" class="container">
                <header>
                    <h3>References</h3>
                </header>
                <ul class="default" style="text-align:left">
                    <li>
                        Chen et. al, "<a href="https://xuchen-ethz.github.io/gdna/" target="_blank">gDNA: Towards Generative Detailed Neural Avatars</a>." CVPR, 2022.
                    </li>
                    <li>
                        Palafox et. al, "<a href="https://pablopalafox.github.io/npms/" target="_blank">NPMs: Neural Parametric Models for 3D Deformable Shapes</a>." ICCV, 2021.
                    </li>
                    <li>
                        Palafox et. al, "<a href="http://www.iri.upc.edu/people/ecorona/smplicit/" target="_blank">SMPLicit: Topology-aware Generative Model for Clothed People</a>." CVPR, 2021.
                    </li>
                    <li>
                        Yu et. al, "<a href="https://github.com/ytrock/THuman2.0-Dataset" target="_blank">Function4D: Real-time Human Volumetric Capture from Very Sparse Consumer RGBD Sensors</a>." CVPR, 2021.
                    </li>
                    <li>
                        Tiwari et. al, "<a href="https://virtualhumans.mpi-inf.mpg.de/sizer/" target="_blank">SIZER: A Dataset and Model for Parsing 3D Clothing and Learning Size Sensitive 3D Clothing</a>." ECCV, 2020.
                    </li>

                </ul>
                <div class="subtitle">
                    <h3>Bibtex</h3>
<pre><cite>@inproceedings{ho2023custom,
    title={Learning Locally Editable Virtual Humans},
    author={Hsuan-I Ho, Lixin Xue, Jie Song, and Otmar Hilliges},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2023}
  }</cite></pre>
                </div>
            </article>


            
        </div>

        <!-- Acknowledgement -->
        <div class="wrapper style3">
            <article>
                <div class="container">
                    <h2>Acknowledgement</h2>
                    <p  style="text-align:left">
                        We express our gratitude to Stefan Walter and Dean Bakker for infrastructure support, Juan Zarate for managing the capture stage, and Deniz Yildiz and Laura Wülfroth for data capture assistance. Thanks to Andrew Searle for supporting the capturing system, and anonymous thanks to all dataset participants.                    </p>
                </div>
            </article>
        </div>
      
        <!-- Copyright -->
        <div class="wrapper last style4">
            <article class="container">
                <footer>
                    <ul id="copyright">
                        <li>&copy; 2023 Hsuan-I Ho.</li><li>Thanks: <a href="http://html5up.net" target="_blank">HTML5 UP</a> and Po-Chen Wu provides this template</li>
                    </ul>
                </footer>
            </article>
        </div>

		<!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/skel.min.js"></script>
        <script src="assets/js/skel-viewport.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>
        <script src="assets/js/materialize.js"></script>
    </body>
</html>
